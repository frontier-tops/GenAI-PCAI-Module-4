{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd03dbf2-7e12-4b6d-b325-2c4f10ea2ab3",
   "metadata": {},
   "source": [
    "# RAG Using Different LLM Endpoints in PCAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc737e3-dc25-4744-9295-7fcd26c2de29",
   "metadata": {},
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0197765d-6014-4434-bb59-daf1ea4534cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "from langchain_nvidia_ai_endpoints.reranking import NVIDIARerank\n",
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d529650-d181-4dff-a9b5-e2bc2ef62bad",
   "metadata": {},
   "source": [
    "## Fetching the Secret Token for RAG Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a304d1-baba-4586-bd23-bddf732c3682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate, os\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "#getting the auth token\n",
    "secret_file_path = \"/etc/secrets/ezua/.auth_token\"\n",
    "\n",
    "with open(secret_file_path, \"r\") as file:\n",
    "    token = file.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb97a8d-2021-4ef5-86fd-66f611bdedf1",
   "metadata": {},
   "source": [
    "## Connecting to Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a85b7-022f-43f6-a730-42f73e969422",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \".cluster.local\"\n",
    "http_host = \"weaviate.hpe-weaviate.svc.cluster.local\"\n",
    "grpc_host = \"weaviate-grpc.hpe-weaviate.svc\" + domain\n",
    "weaviate_headers = {\"x-auth-token\": token}\n",
    "#weaviate_headers = {\"x-auth-token\": \"wrong token\"}\n",
    "\n",
    "client = weaviate.connect_to_custom(\n",
    "    http_host=http_host,        # Hostname for the HTTP API connection\n",
    "    http_port=80,              # Default is 80, WCD uses 443\n",
    "    http_secure=False,           # Whether to use https (secure) for the HTTP API connection\n",
    "    grpc_host=grpc_host,        # Hostname for the gRPC API connection\n",
    "    grpc_port=50051,              # Default is 50051, WCD uses 443\n",
    "    grpc_secure=False,           # Whether to use a secure channel for the gRPC API connection\n",
    "    headers=weaviate_headers,\n",
    "    skip_init_checks=False\n",
    ")\n",
    "\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ece543-14fc-483b-8162-a7877b719039",
   "metadata": {},
   "source": [
    "# RUN ONLY THE CELL THAT YOU WANT TO ACCESS YOUR LLM THROUGH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a831d6c5-b101-4d9a-a582-b55fec175991",
   "metadata": {},
   "source": [
    "## Connecting to LLM through MLIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a5b1b-b534-461c-9a14-93a012db27c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_api_key = \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3NDc0ODMxMzEsImlhdCI6MTc0NDg5MTEzMywiaXNzIjoiYWlvbGlAaHBlLmNvbSIsInN1YiI6ImE2ODU0ZjJhLWQ0NGItNGY2MC04N2EwLTEyOGU4YmY2N2JhZCIsInVzZXIiOiJnZW5haS0wMS10bWVob2wubmV0In0.mvLeYBTwIpCuun5frO6SIxPdDbUlkhO26BYQci38osk5YeUheed2zOn8iTHHxqmYydg7jJRvv61mlzgwj9E59QcOCl8UAComSudralRgvDuSthv-9nExi1lw_6qNhs8WjhKl9r2f2eNJ-vLIKHQTZDZkzUz1-gaOC_TmQzQgtvDoBeJOY_5jULrR88n22jQY8_lOdypDQBG1u7bIVOCdy-YcEzbfOTDTIsoTcGqw19J7arDi0IzrUZmbnlhmqgQ9LRj3KBmkvv-t-db5LfGCbpFW7EZU0lzJ5wA2eMKo3Cfam1Wzlne36QDCWvxVUD9blhc8Q8Q_hEGVQytjECr6Sw\"\n",
    "\n",
    "llm = ChatNVIDIA(\n",
    "    base_url=\"https://nvidia-nim-model-predictor-genai-01-tmehol-net-f5874609.pcai1.genai1.hou\",\n",
    "    model=\"meta/llama3-8b-instruct\",\n",
    "    api_key=_api_key,\n",
    "    temperature=0.5,\n",
    "    max_tokens=1024,\n",
    "    top_p=1.0,\n",
    ")\n",
    "llm.invoke(\"what is an api?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b74898d-a73f-4ede-831c-6832fb995102",
   "metadata": {},
   "source": [
    "## Connecting to LLM Through RAG ESSENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753ad95-48af-4376-81e5-d5d0ec855a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatNVIDIA(\n",
    "    base_url=\"https://llama-3-1-8b-b7ee1686-predictor-ezai-services.pcai1.genai1.hou\",\n",
    "    model=\"meta/llama-3.1-8b-instruct\",\n",
    "    api_key=token,\n",
    "    temperature=0.5,\n",
    "    max_tokens=1024,\n",
    "    top_p=1.0,\n",
    ")\n",
    "llm.invoke(\"what is an api?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd50eaf-0147-491b-a3f8-50590bee7115",
   "metadata": {},
   "source": [
    "## Connecting to LLM through OLLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5823f7c-fcc9-439f-9239-9d73c78612a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.3:70b\",\n",
    "    base_url=\"https://ollama.pcai1.genai1.hou\",\n",
    ")\n",
    "llm.invoke(\"what is an api?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d1851-c89b-4a96-908d-73978a46498a",
   "metadata": {},
   "source": [
    "## Data Extraction and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74087bad-8c82-4c54-bbd3-033e77ffaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the path to your PDF\n",
    "pdf_path = \"./HPE.pdf\"\n",
    "\n",
    "# Load PDF file\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Split into manageable chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "for doc in docs:\n",
    "    doc.metadata={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b8b83e-3e1b-48c2-99e3-1ba7d4fab411",
   "metadata": {},
   "source": [
    "## Vector Store Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22599776-f7c7-47fc-84f9-8946f8da9d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "vector = WeaviateVectorStore.from_documents(docs, embedding=OllamaEmbeddings(model = \"nomic-embed-text:latest\", base_url=\"https://ollama.pcai1.genai1.hou\"), client=client, index_name=\"RAG\", text_key=\"Rag\".lower() + \"_key\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eedbd2-d552-473f-b4b3-69adb44f38c2",
   "metadata": {},
   "source": [
    "## Retriever Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73394d2-b53b-414c-b0dc-a0d86327a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b221ae9-07f6-462c-a916-e83d01b511a8",
   "metadata": {},
   "source": [
    "## Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2d767-9425-461c-9b79-27af7ad4bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = NVIDIARerank(model=\"nvidia/nv-rerankqa-mistral-4b-v3\",\n",
    "                          base_url=\"https://reranker-5c3f14b5-predictor-ezai-services.pcai1.genai1.hou\",\n",
    "                          api_key=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f66049a-8cba-4b4a-a09d-cdbdf7e120e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=retriever\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1786bc9-a8a3-49c9-b57a-effdd202942b",
   "metadata": {},
   "source": [
    "## User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a345a03-46b7-4c5d-8dba-86d8ae0f0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is HPE Proliant Compute DL384 Gen12\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e7c476-1e68-4797-a428-62a3893e1c4d",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d6a4fc-832c-4e02-91aa-a174d8212e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
